{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9feebade",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'generate_string' from 'llm' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseModel, Field\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m generate_string, openai_llm\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mCostarPrompt\u001b[39;00m:\n\u001b[32m      6\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Represents the CO-STAR framework prompt structure.\"\"\"\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'generate_string' from 'llm' (unknown location)"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from llm import generate_string, openai_llm\n",
    "\n",
    "class CostarPrompt:\n",
    "    \"\"\"Represents the CO-STAR framework prompt structure.\"\"\"\n",
    "\n",
    "    def __init__(self, context=None, objective=None, style=None, tone=None, audience=None, response=None):\n",
    "        self.context = context\n",
    "        self.objective = objective\n",
    "        self.style = style\n",
    "        self.tone = tone\n",
    "        self.audience = audience\n",
    "        self.response = response\n",
    "\n",
    "    def __str__(self):\n",
    "        costar_prompt = \"\"\n",
    "        if self.context:\n",
    "            costar_prompt += \"# CONTEXT #\\n\" + self.context + \"\\n\"\n",
    "        if self.objective:\n",
    "            costar_prompt += \"# OBJECTIVE #\\n\" + self.objective + \"\\n\"\n",
    "        if self.style:\n",
    "            costar_prompt += \"# STYLE #\\n\" + self.style + \"\\n\"\n",
    "        if self.tone:\n",
    "            costar_prompt += \"# TONE #\\n\" + self.tone + \"\\n\"\n",
    "        if self.audience:\n",
    "            costar_prompt += \"# AUDIENCE #\\n\" + self.audience + \"\\n\"\n",
    "        if self.response:\n",
    "            costar_prompt += \"# RESPONSE #\\n\" + self.response + \"\\n\"\n",
    "        return costar_prompt\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "\n",
    "class Translator:\n",
    "    def __init__(self, show_prompt=False):\n",
    "        self.show_prompt = show_prompt\n",
    "        self.last_prompts = {}\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # STEP 1: Section Header Translation\n",
    "    # -----------------------------------------------------------\n",
    "    def translate_section_header(self, source_text: str, source_lang: str, target_lang: str):\n",
    "        \"\"\"Translate a short section header term.\"\"\"\n",
    "        costar_prompt = CostarPrompt(\n",
    "            context=f\"You are a Translator for a bank, translating financial terminology from {source_lang} to {target_lang}.\",\n",
    "            objective=f\"Translate the given term '{source_text}' from {source_lang} to {target_lang}.\",\n",
    "            audience=\"Your audience is the bank's investment report senior editor.\",\n",
    "            response=f\"Output just the translated term of '{source_text}' in {target_lang}. Do not include explanations or any additional text.\"\n",
    "        )\n",
    "\n",
    "        llm = openai_llm(temperature=0)\n",
    "        result = generate_string(\n",
    "            llm, str(costar_prompt), {}, show_prompt=self.show_prompt, system_prompt_only=True\n",
    "        )\n",
    "        return result.content\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # STEP 2: Full Translation\n",
    "    # -----------------------------------------------------------\n",
    "    def translate(self, source_text: str, source_lang: str, target_lang: str):\n",
    "        \"\"\"Perform initial translation in the tone of financial reports.\"\"\"\n",
    "        costar_prompt = CostarPrompt(\n",
    "            context=f\"You are a Translator for a bank, translating financial text such as investment reports from {source_lang} to {target_lang}.\",\n",
    "            objective=f\"Translate the text '{source_text}' from {source_lang} to {target_lang}. Tone should match the style of a financial report.\",\n",
    "            audience=\"Your audience is the bank's investment report senior editor.\",\n",
    "            response=f\"Output just the translation of '{source_text}' in {target_lang}, with no explanation or introduction.\"\n",
    "        )\n",
    "\n",
    "        llm = openai_llm(temperature=0)\n",
    "        result = generate_string(\n",
    "            llm, str(costar_prompt), {}, show_prompt=self.show_prompt, system_prompt_only=True\n",
    "        )\n",
    "        return result.content\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # STEP 3: Refinement (After Editor Suggestions)\n",
    "    # -----------------------------------------------------------\n",
    "    def refine_translation(self, source_text: str, initial_translated_text: str, improvements: str,\n",
    "                           source_lang: str, target_lang: str):\n",
    "        \"\"\"Refine translation based on editor's improvement suggestions.\"\"\"\n",
    "        costar_prompt = CostarPrompt(\n",
    "            context=f\"You are a Translator for a bank, refining translations from {source_lang} to {target_lang} based on senior editor feedback.\",\n",
    "            objective=f\"Given the initial translation:\\n'{initial_translated_text}'\\nand editor's comments:\\n'{improvements}'\\nrework the translation accordingly.\",\n",
    "            audience=\"Your audience is the bank's investment report senior editor.\",\n",
    "            response=f\"Output the final refined translation in {target_lang} only — no explanations, just the text.\"\n",
    "        )\n",
    "\n",
    "        llm = openai_llm(temperature=0)\n",
    "        result = generate_string(\n",
    "            llm, str(costar_prompt), {}, show_prompt=self.show_prompt, system_prompt_only=True\n",
    "        )\n",
    "        return result.content\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # STEP 4: Editor Comments Generation\n",
    "    # -----------------------------------------------------------\n",
    "    def editor_comments(self, source_text: str, translated_text: str, target_lang: str):\n",
    "        \"\"\"Generate feedback from senior editor on translation quality.\"\"\"\n",
    "        costar_prompt = CostarPrompt(\n",
    "            context=\"You are a senior linguistic expert that specializes in financial text translation.\",\n",
    "            objective=f\"\"\"\n",
    "            Based on the translated text below produced by a junior translator, provide constructive comments to improve the output.\n",
    "\n",
    "            ### Source Text ###\n",
    "            {source_text}\n",
    "\n",
    "            ### Translated Text ###\n",
    "            {translated_text}\n",
    "\n",
    "            When writing your suggestions, pay attention to whether there are ways to improve the translation's:\n",
    "            (i) accuracy (by correcting errors of addition, mistranslation, omission, or untranslated text),\n",
    "            (ii) fluency (by applying {target_lang} grammar, spelling, and punctuation rules, and ensuring there are no unnecessary repetitions unless in report headers),\n",
    "            (iii) style (by ensuring the translations reflect the tone of a financial report),\n",
    "            (iv) terminology (by ensuring terminology use is consistent with the financial domain in {target_lang}).\n",
    "            \"\"\",\n",
    "            audience=\"Your audience is the bank's translator who will revise the translation based on your comments.\",\n",
    "            response=\"Provide your improvement suggestions in concise bullet points.\"\n",
    "        )\n",
    "\n",
    "        llm = openai_llm(temperature=0)\n",
    "        suggestion = generate_string(\n",
    "            llm, str(costar_prompt), {}, show_prompt=self.show_prompt, system_prompt_only=True\n",
    "        )\n",
    "        return suggestion.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c713834f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain.schema import BaseOutputParser\n",
    "# from translator import Translator\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# === TOOL: terminology lookup ==================================================\n",
    "def terminology_lookup(term: str) -> str | None:\n",
    "    \"\"\"Lookup financial terminology from terminology.csv\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(\"terminology.csv\")\n",
    "        match = df[df['ENGLISH'].str.lower() == term.lower()]\n",
    "        if not match.empty:\n",
    "            return match.iloc[0]['CHINESE']\n",
    "    except Exception as e:\n",
    "        print(f\"Terminology lookup failed: {e}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "# === AGENT: refinement agent ===================================================\n",
    "class RefinementAgent:\n",
    "    def __init__(self):\n",
    "        self.translator = Translator(show_prompt=False)\n",
    "\n",
    "    def __call__(self, state: dict) -> dict:\n",
    "        \"\"\"\n",
    "        Executes the Refinement step.\n",
    "        Input state should include:\n",
    "        {\n",
    "            \"source_text\": \"...\",\n",
    "            \"initial_translation\": \"...\",\n",
    "            \"target_lang\": \"Chinese\",\n",
    "            \"source_lang\": \"English\"\n",
    "        }\n",
    "        \"\"\"\n",
    "        source_text = state[\"source_text\"]\n",
    "        initial_translation = state[\"initial_translation\"]\n",
    "        source_lang = state.get(\"source_lang\", \"English\")\n",
    "        target_lang = state.get(\"target_lang\", \"Chinese\")\n",
    "\n",
    "        # 1️⃣ Get editor-style comments automatically\n",
    "        editor_feedback = self.translator.editor_comments(\n",
    "            source_text, initial_translation, target_lang\n",
    "        )\n",
    "\n",
    "        # 2️⃣ Attempt terminology enhancement\n",
    "        words = source_text.split()\n",
    "        for w in words:\n",
    "            translated_term = terminology_lookup(w)\n",
    "            if translated_term:\n",
    "                initial_translation = initial_translation.replace(w, translated_term)\n",
    "\n",
    "        # 3️⃣ Refine translation based on the feedback\n",
    "        final_translation = self.translator.refine_translation(\n",
    "            source_text=source_text,\n",
    "            initial_translated_text=initial_translation,\n",
    "            improvements=editor_feedback,\n",
    "            source_lang=source_lang,\n",
    "            target_lang=target_lang,\n",
    "        )\n",
    "\n",
    "        # 4️⃣ Return new graph state\n",
    "        return {\n",
    "            **state,\n",
    "            \"editor_feedback\": editor_feedback,\n",
    "            \"refined_translation\": final_translation,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15b55bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='PBT利润率在第二季度相比于第一季度增加了15%。' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 75, 'total_tokens': 90, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CVh3pqbAWb5091gyKD8lnLTfoz8fj', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--050fe826-bc82-4f2b-bd98-00c007031d20-0' usage_metadata={'input_tokens': 75, 'output_tokens': 15, 'total_tokens': 90, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "PBT利润率在第二季度相比于第一季度增加了15%。\n"
     ]
    }
   ],
   "source": [
    "translated_text = direct_translate(\n",
    "    source_text=\"PBT Margin increased by 15% in Q2 compared to Q1.\",\n",
    "    source_lang=\"English\",\n",
    "    target_lang=\"Mandarin\"\n",
    ")\n",
    "\n",
    "\n",
    "print(translated_text)\n",
    "# → Bank pusat menaikkan kadar faedah sebanyak 25 mata asas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "351ea33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'中央银行将利率上调了25个基点.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fb54da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools/terminology_lookup.py\n",
    "import pandas as pd\n",
    "\n",
    "# Example CSV (financial terminology)\n",
    "# term,official_translation\n",
    "# Emerging Markets,Pasaran Muncul\n",
    "# AAPL,Apple Inc.\n",
    "\n",
    "TERMINOLOGY_FILE = \"terminology.csv\"\n",
    "\n",
    "def terminology_lookup(term: str) -> str | None:\n",
    "    df = pd.read_csv(TERMINOLOGY_FILE)\n",
    "    row = df[df[\"term\"].str.lower() == term.lower()]\n",
    "    if not row.empty:\n",
    "        return row.iloc[0][\"official_translation\"]\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82d57522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)\n",
    "\n",
    "# State definition for LangGraph\n",
    "from typing import TypedDict, List\n",
    "\n",
    "class RefinementState(TypedDict):\n",
    "    source_text: str\n",
    "    direct_translation: str\n",
    "    target_language: str\n",
    "    locale: str\n",
    "    refined_output: str\n",
    "    terminology_calls: List[dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c1a5210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refinement_node(state: RefinementState):\n",
    "    source = state[\"source_text\"]\n",
    "    translated = state[\"direct_translation\"]\n",
    "    target_lang = state[\"target_language\"]\n",
    "    locale = state[\"locale\"]\n",
    "\n",
    "    # Step 1: Ask LLM what terms might need checking\n",
    "    analysis_prompt = (\n",
    "        \"You are a financial language expert.\\n\"\n",
    "        \"Identify any financial terms or tickers in the text that may need \"\n",
    "        \"official terminology lookup.\\n\"\n",
    "        \"Return them as a comma-separated list only.\"\n",
    "    )\n",
    "    analysis_response = llm.invoke([\n",
    "        SystemMessage(content=analysis_prompt),\n",
    "        HumanMessage(content=translated)\n",
    "    ])\n",
    "    terms_to_check = [t.strip() for t in analysis_response.content.split(\",\") if t.strip()]\n",
    "\n",
    "    terminology_calls = []\n",
    "    replacements = {}\n",
    "\n",
    "    # Step 2: Lookup each term\n",
    "    for term in terms_to_check:\n",
    "        translation = terminology_lookup(term)\n",
    "        terminology_calls.append({\"term\": term, \"translation\": translation})\n",
    "        if translation:\n",
    "            replacements[term] = translation\n",
    "\n",
    "    # Step 3: Ask LLM to refine the text with these corrections\n",
    "    refinement_prompt = (\n",
    "        f\"You are a localization expert. Rewrite the translation for {target_lang} ({locale}) readers.\\n\"\n",
    "        \"Improve flow and readability, but preserve original meaning.\\n\"\n",
    "        \"Incorporate the following official term translations:\\n\"\n",
    "        f\"{replacements}\\n\"\n",
    "        \"Output only the refined translation.\"\n",
    "    )\n",
    "\n",
    "    refinement_response = llm.invoke([\n",
    "        SystemMessage(content=refinement_prompt),\n",
    "        HumanMessage(content=translated)\n",
    "    ])\n",
    "\n",
    "    state[\"refined_output\"] = refinement_response.content.strip()\n",
    "    state[\"terminology_calls\"] = terminology_calls\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "837ed869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build graph\n",
    "graph = StateGraph(RefinementState)\n",
    "graph.add_node(\"refine\", refinement_node)\n",
    "graph.set_entry_point(\"refine\")\n",
    "graph.set_finish_point(\"refine\")\n",
    "\n",
    "app = graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c6d23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dana ini melabur terutamanya di Pasaran Baru Muncul seperti Malaysia dan Indonesia.\n",
      "[{'term': 'Pasaran Baru Muncul', 'translation': None}]\n"
     ]
    }
   ],
   "source": [
    "init_state = {\n",
    "    \"source_text\": \"The fund invests primarily in Emerging Markets like Malaysia and Indonesia.\",\n",
    "    \"direct_translation\": \"PBT利润率在第二季度相比于第一季度增加了15%.\",\n",
    "    \"target_language\": \"Mandarin\",\n",
    "    \"locale\": \"MY\",\n",
    "}\n",
    "\n",
    "final_state = app.invoke(init_state)\n",
    "print(final_state[\"refined_output\"])\n",
    "print(final_state[\"terminology_calls\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b258ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
