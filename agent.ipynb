{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86e78226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import convert_to_messages\n",
    "import os\n",
    "\n",
    "def pretty_print_message(message, indent=False):\n",
    "    pretty_message = message.pretty_repr(html=True)\n",
    "    if not indent:\n",
    "        print(pretty_message)\n",
    "        return\n",
    "\n",
    "    indented = \"\\n\".join(\"\\t\" + c for c in pretty_message.split(\"\\n\"))\n",
    "    print(indented)\n",
    "\n",
    "\n",
    "def pretty_print_messages(update, last_message=False):\n",
    "    is_subgraph = False\n",
    "    if isinstance(update, tuple):\n",
    "        ns, update = update\n",
    "        # skip parent graph updates in the printouts\n",
    "        if len(ns) == 0:\n",
    "            return\n",
    "\n",
    "        graph_id = ns[-1].split(\":\")[0]\n",
    "        print(f\"Update from subgraph {graph_id}:\")\n",
    "        print(\"\\n\")\n",
    "        is_subgraph = True\n",
    "\n",
    "    for node_name, node_update in update.items():\n",
    "        update_label = f\"Update from node {node_name}:\"\n",
    "        if is_subgraph:\n",
    "            update_label = \"\\t\" + update_label\n",
    "\n",
    "        print(update_label)\n",
    "        print(\"\\n\")\n",
    "\n",
    "        messages = convert_to_messages(node_update[\"messages\"])\n",
    "        if last_message:\n",
    "            messages = messages[-1:]\n",
    "\n",
    "        for m in messages:\n",
    "            pretty_print_message(m, indent=is_subgraph)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4d096ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool, initialize_agent\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.tools import tool\n",
    "from langgraph.graph import END, StateGraph\n",
    "from typing import List, Dict\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from langsmith import traceable\n",
    "from langsmith.wrappers import wrap_openai\n",
    "import os\n",
    "\n",
    "LANGSMITH_TRACING=\"true\"\n",
    "LANGSMITH_ENDPOINT=\"https://api.smith.langchain.com\"\n",
    "LANGSMITH_PROJECT=\"news-agent\"\n",
    "\n",
    "\n",
    "TARGET_AUTHORS = {\n",
    "    \"HLInvest\"\n",
    "}\n",
    "\n",
    "TARGET_DATE = \"25 July 2025\"  # Change as needed\n",
    "HEADERS = {\"User-Agent\": \"Mozilla/5.0 (compatible; NewsScraper/1.0)\"}\n",
    "BASE_URL = \"https://klse.i3investor.com\"\n",
    "IMAGE_FOLDER = \"technical_charts\"\n",
    "\n",
    "\n",
    "# -- 2.1 Headline Extraction Agent --\n",
    "@tool\n",
    "def fetch_headlines_agent():\n",
    "    \"\"\"\n",
    "    Getting the news headlines and the associated url to the blog from the i3investor blog page.\n",
    "    \"\"\"\n",
    "    url = f\"{BASE_URL}/web/headline/blog?type=research\"\n",
    "    resp = requests.get(url, headers=HEADERS, timeout=10)\n",
    "    resp.raise_for_status()\n",
    "\n",
    "    html = resp.text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    container = soup.select_one(\"#news-blog\")\n",
    "    results = []\n",
    "\n",
    "    current_date = None\n",
    "    for el in container.find_all(recursive=False):\n",
    "        h5 = el.select_one(\"h5\")\n",
    "        if h5:\n",
    "            match = re.search(r\"\\d{1,2} \\w+ \\d{4}\", h5.text)\n",
    "            if match:\n",
    "                current_date = match.group(0)\n",
    "            continue\n",
    "\n",
    "        if el.name == \"ul\" and \"ms-4\" in el.get(\"class\", []):\n",
    "            li = el.select_one(\"li\")\n",
    "            if not li:\n",
    "                continue\n",
    "            a_tag = li.find(\"a\", href=True)\n",
    "            subtitle = li.select_one(\"span.subtitle a\")\n",
    "            if not a_tag or not subtitle:\n",
    "                continue\n",
    "            author = subtitle.text.strip()\n",
    "            if author not in TARGET_AUTHORS:\n",
    "                continue\n",
    "            if current_date != TARGET_DATE:\n",
    "                continue\n",
    "\n",
    "            full_url = a_tag[\"href\"] if a_tag[\"href\"].startswith(\"http\") else BASE_URL + a_tag[\"href\"]\n",
    "\n",
    "            results.append({\n",
    "                \"title\": a_tag.text.strip(),\n",
    "                \"author\": author,\n",
    "                \"date\": current_date,\n",
    "                \"url\": full_url\n",
    "            })\n",
    "\n",
    "    return {\"results\": results}\n",
    "\n",
    "# -- 2.2 Blog Parser Agent (content structuring) --\n",
    "@tool\n",
    "def parse_blog_content_agent(item: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Fetches results from fetch_headlines_agent and parses blog post content from url and extracts clean text and images.\n",
    "    \"\"\"\n",
    "    resp = requests.get(url, headers=HEADERS, timeout=10)\n",
    "    resp.raise_for_status()\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "    content_div = soup.select_one(\"#blogcontent\")\n",
    "    if not content_div:\n",
    "        return {\"text\": \"\", \"images\": []}\n",
    "\n",
    "    # Extract text content\n",
    "    content_parts = []\n",
    "    for tag in content_div.find_all([\"h3\", \"p\", \"li\"], recursive=True):\n",
    "        content_parts.append(tag.get_text(strip=True))\n",
    "\n",
    "    # Extract images\n",
    "    os.makedirs(IMAGE_FOLDER, exist_ok=True)\n",
    "    image_filenames = []\n",
    "    for img_tag in content_div.find_all(\"img\"):\n",
    "        src = img_tag.get(\"src\")\n",
    "        if not src:\n",
    "            continue\n",
    "        img_url = BASE_URL + src if src.startswith(\"/\") else src\n",
    "        filename = os.path.basename(img_url)  # âœ… only save filename\n",
    "        filepath = os.path.join(IMAGE_FOLDER, filename)\n",
    "\n",
    "        try:\n",
    "            img_resp = requests.get(img_url, headers=HEADERS)\n",
    "            img_resp.raise_for_status()\n",
    "            with open(filepath, \"wb\") as f:\n",
    "                f.write(img_resp.content)\n",
    "            print(f\"ðŸ–¼ï¸  Saved image: {filepath}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸  Failed to download image {img_url}: {e}\")\n",
    "            continue\n",
    "\n",
    "        image_filenames.append(filename)\n",
    "\n",
    "    return {\n",
    "        \"text\": \"\\n\".join(content_parts),\n",
    "        \"images\": image_filenames\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    # reasoning_format=\"hidden\",\n",
    "    timeout=None,\n",
    "    max_retries=0,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f28f6028",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "\n",
    "fetch_headlines_agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=[fetch_headlines_agent],\n",
    "    prompt=(\n",
    "        \"You are a web scraper agent that scrapes the headlines page from https://klse.i3investor.com/web/headline/blog\\n\\n\"\n",
    "        \"INSTRUCTIONS:\\n\"\n",
    "        \"- Respond ONLY with the results of your work, do NOT include ANY other text.\"\n",
    "    ),\n",
    "    name=\"fetch_headlines_agent\",\n",
    ")\n",
    "\n",
    "\n",
    "parse_blog_content_agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=[parse_blog_content_agent],\n",
    "    prompt=(\n",
    "        \"You are a web-scraping for detailed blog page agent. \\n\\n\"\n",
    "        \"INSTRUCTIONS:\\n\"\n",
    "        \"- Respond ONLY with the results of your work, do NOT include ANY other text.\"\n",
    "    ),\n",
    "    name=\"parse_blog_content_agent\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ce12ac5",
   "metadata": {},
   "outputs": [
    {
     "ename": "GraphRecursionError",
     "evalue": "Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mGraphRecursionError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m      9\u001b[39m supervisor = (\n\u001b[32m     10\u001b[39m     StateGraph(MessagesState)\n\u001b[32m     11\u001b[39m     \u001b[38;5;66;03m# NOTE: `destinations` is only needed for visualization and doesn't affect runtime behavior\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m     .compile()\n\u001b[32m     18\u001b[39m )\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# from IPython.display import display, Image\u001b[39;00m\n\u001b[32m     21\u001b[39m \n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# display(Image(supervisor.get_graph().draw_mermaid_png()))\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msupervisor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat is the news headlines for today?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretty_print_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_message\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gooyt\\Desktop\\ai-news-agent\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2534\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2532\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2533\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2534\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2535\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2536\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2537\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2538\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2539\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2540\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2541\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2542\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2543\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2544\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gooyt\\Desktop\\ai-news-agent\\.venv\\Lib\\site-packages\\langgraph\\pregel\\runner.py:162\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    160\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gooyt\\Desktop\\ai-news-agent\\.venv\\Lib\\site-packages\\langgraph\\pregel\\retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gooyt\\Desktop\\ai-news-agent\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:623\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    621\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    622\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m623\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    625\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gooyt\\Desktop\\ai-news-agent\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2844\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, **kwargs)\u001b[39m\n\u001b[32m   2841\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   2842\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2844\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2845\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2846\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2847\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   2848\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   2849\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2850\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2851\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2852\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2853\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2854\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2855\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2856\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2857\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gooyt\\Desktop\\ai-news-agent\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2559\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2550\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m loop.status == \u001b[33m\"\u001b[39m\u001b[33mout_of_steps\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2551\u001b[39m     msg = create_error_message(\n\u001b[32m   2552\u001b[39m         message=(\n\u001b[32m   2553\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRecursion limit of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[33m'\u001b[39m\u001b[33mrecursion_limit\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m reached \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2557\u001b[39m         error_code=ErrorCode.GRAPH_RECURSION_LIMIT,\n\u001b[32m   2558\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2559\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m GraphRecursionError(msg)\n\u001b[32m   2560\u001b[39m \u001b[38;5;66;03m# set final channel values as run output\u001b[39;00m\n\u001b[32m   2561\u001b[39m run_manager.on_chain_end(loop.output)\n",
      "\u001b[31mGraphRecursionError\u001b[39m: Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT",
      "During task with name 'fetch_headlines_agent' and id '4409aa6c-4b49-dd7b-2bae-cc92439f654f'"
     ]
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "from langchain_core.tools import tool, InjectedToolCallId\n",
    "from langgraph.prebuilt import InjectedState\n",
    "from langgraph.graph import StateGraph, START, MessagesState\n",
    "from langgraph.types import Command\n",
    "from langgraph.graph import END\n",
    "\n",
    "# Define the multi-agent supervisor graph\n",
    "supervisor = (\n",
    "    StateGraph(MessagesState)\n",
    "    # NOTE: `destinations` is only needed for visualization and doesn't affect runtime behavior\n",
    "    .add_node(fetch_headlines_agent)\n",
    "    .add_node(parse_blog_content_agent)\n",
    "    .add_edge(START, \"fetch_headlines_agent\")\n",
    "    .add_edge(\"fetch_headlines_agent\", \"parse_blog_content_agent\")\n",
    "    .add_edge(\"parse_blog_content_agent\", END)\n",
    "    .compile()\n",
    ")\n",
    "\n",
    "# from IPython.display import display, Image\n",
    "\n",
    "# display(Image(supervisor.get_graph().draw_mermaid_png()))\n",
    "\n",
    "for chunk in supervisor.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What is the news headlines for today?\",\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "):\n",
    "    pretty_print_messages(chunk, last_message=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f2700c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update from node supervisor:\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: transfer_to_parse_headlines_agent\n",
      "\n",
      "Successfully transferred to parse_headlines_agent\n",
      "\n",
      "\n",
      "Update from node parse_headlines_agent:\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: parse_headlines_agent\n",
      "\n",
      "{\"headlines\": [{\"title\": \"Traders Brief - HLIB Retail Research â€“25 July\", \"author\": \"HLInvest\", \"date\": \"25 July 2025\", \"url\": \"https://klse.i3investor.com/web/blog/detail/hleresearch/2025-07-25-story-h499657040-Traders_Brief_HLIB_Retail_Research_ndash_25_July\"}]}\n",
      "\n",
      "\n",
      "Update from node supervisor:\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: supervisor\n",
      "\n",
      " \n",
      "\n",
      "The current news headlines for today include \"Traders Brief - HLIB Retail Research â€“25 July\" by HLInvest, dated 25 July 2025, and can be found at https://klse.i3investor.com/web/blog/detail/hleresearch/2025-07-25-story-h499657040-Traders_Brief_HLIB_Retail_Research_ndash_25_July.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "\n",
    "fetch_headlines_agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=[fetch_headlines_agent],\n",
    "    prompt=(\n",
    "        \"You are a web scraper agent that scrapes the headlines page from https://klse.i3investor.com/web/headline/blog\\n\\n\"\n",
    "        \"INSTRUCTIONS:\\n\"\n",
    "        \"- Assist ONLY getting the headlines tasks, DO NOT do any deep crawling\\n\"\n",
    "        \"- After you're done with your tasks, respond to the supervisor directly\\n\"\n",
    "        \"- Respond ONLY with the results of your work, do NOT include ANY other text.\"\n",
    "    ),\n",
    "    name=\"fetch_headlines_agent\",\n",
    ")\n",
    "\n",
    "\n",
    "parse_blog_content_agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=[parse_blog_content_agent],\n",
    "    prompt=(\n",
    "        \"You are a web-scraping for detailed blog page agent. DO NOT use this if user only request to know the headlines\\n\\n\"\n",
    "        \"INSTRUCTIONS:\\n\"\n",
    "        \"- Assist ONLY with extracting blog post content from url and extracts clean text and images tasks\\n\"\n",
    "        \"- After you're done with your tasks, respond to the supervisor directly\\n\"\n",
    "        \"- Respond ONLY with the results of your work, do NOT include ANY other text.\"\n",
    "    ),\n",
    "    name=\"parse_blog_content_agent\",\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from typing import Annotated\n",
    "from langchain_core.tools import tool, InjectedToolCallId\n",
    "from langgraph.prebuilt import InjectedState\n",
    "from langgraph.graph import StateGraph, START, MessagesState\n",
    "from langgraph.types import Command\n",
    "\n",
    "\n",
    "def create_handoff_tool(*, agent_name: str, description: str | None = None):\n",
    "    name = f\"transfer_to_{agent_name}\"\n",
    "    description = description or f\"Ask {agent_name} for help.\"\n",
    "\n",
    "    @tool(name, description=description)\n",
    "    def handoff_tool(\n",
    "        state: Annotated[MessagesState, InjectedState],\n",
    "        tool_call_id: Annotated[str, InjectedToolCallId],\n",
    "    ) -> Command:\n",
    "        tool_message = {\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": f\"Successfully transferred to {agent_name}\",\n",
    "            \"name\": name,\n",
    "            \"tool_call_id\": tool_call_id,\n",
    "        }\n",
    "        return Command(\n",
    "            goto=agent_name,  \n",
    "            update={**state, \"messages\": state[\"messages\"] + [tool_message]},  \n",
    "            graph=Command.PARENT,  \n",
    "        )\n",
    "\n",
    "    return handoff_tool\n",
    "\n",
    "\n",
    "# Handoffs\n",
    "assign_to_fetch_headlines_agent = create_handoff_tool(\n",
    "    agent_name=\"fetch_headlines_agent\",\n",
    "    description=\"Assign task to a parse_headlines agent.\",\n",
    ")\n",
    "\n",
    "assign_to_parse_blog_content_agent = create_handoff_tool(\n",
    "    agent_name=\"parse_blog_content_agent\",\n",
    "    description=\"Assign task to a parse_blog_content agent.\",\n",
    ")\n",
    "\n",
    "\n",
    "supervisor_agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=[assign_to_fetch_headlines_agent, assign_to_parse_blog_content_agent],\n",
    "    prompt=(\n",
    "        \"You are a supervisor managing two agents:\\n\"\n",
    "        \"- a news headlines agent. Assign headlines research (including title, author, urls, date) tasks to this agent\\n\"\n",
    "        \"- a blog content agent. Assign extracting detailed blog content tasks to this agent\\n\"\n",
    "        \"Assign work to one agent at a time, do not call agents in parallel.\\n\"\n",
    "        \"After all agents have completed their tasks, answer the user's question using the collected outputs.\"\n",
    "    ),\n",
    "    name=\"supervisor\",\n",
    ")\n",
    "\n",
    "from langgraph.graph import END\n",
    "\n",
    "# Define the multi-agent supervisor graph\n",
    "supervisor = (\n",
    "    StateGraph(MessagesState)\n",
    "    # NOTE: `destinations` is only needed for visualization and doesn't affect runtime behavior\n",
    "    .add_node(supervisor_agent, destinations=(\"fetch_headlines_agent\", \"parse_blog_content_agent\", END))\n",
    "    .add_node(fetch_headlines_agent)\n",
    "    .add_node(parse_blog_content_agent)\n",
    "    .add_edge(START, \"supervisor\")\n",
    "    # always return back to the supervisor\n",
    "    .add_edge(\"fetch_headlines_agent\", \"supervisor\")\n",
    "    .add_edge(\"parse_blog_content_agent\", \"supervisor\")\n",
    "    .compile()\n",
    ")\n",
    "\n",
    "# from IPython.display import display, Image\n",
    "\n",
    "# display(Image(supervisor.get_graph().draw_mermaid_png()))\n",
    "\n",
    "for chunk in supervisor.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What is the news headlines for today?\",\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "):\n",
    "    pretty_print_messages(chunk, last_message=True)\n",
    "\n",
    "final_message_history = chunk[\"supervisor\"][\"messages\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
