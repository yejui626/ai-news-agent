{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86e78226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import convert_to_messages\n",
    "\n",
    "\n",
    "def pretty_print_message(message, indent=False):\n",
    "    pretty_message = message.pretty_repr(html=True)\n",
    "    if not indent:\n",
    "        print(pretty_message)\n",
    "        return\n",
    "\n",
    "    indented = \"\\n\".join(\"\\t\" + c for c in pretty_message.split(\"\\n\"))\n",
    "    print(indented)\n",
    "\n",
    "\n",
    "def pretty_print_messages(update, last_message=False):\n",
    "    is_subgraph = False\n",
    "    if isinstance(update, tuple):\n",
    "        ns, update = update\n",
    "        # skip parent graph updates in the printouts\n",
    "        if len(ns) == 0:\n",
    "            return\n",
    "\n",
    "        graph_id = ns[-1].split(\":\")[0]\n",
    "        print(f\"Update from subgraph {graph_id}:\")\n",
    "        print(\"\\n\")\n",
    "        is_subgraph = True\n",
    "\n",
    "    for node_name, node_update in update.items():\n",
    "        update_label = f\"Update from node {node_name}:\"\n",
    "        if is_subgraph:\n",
    "            update_label = \"\\t\" + update_label\n",
    "\n",
    "        print(update_label)\n",
    "        print(\"\\n\")\n",
    "\n",
    "        messages = convert_to_messages(node_update[\"messages\"])\n",
    "        if last_message:\n",
    "            messages = messages[-1:]\n",
    "\n",
    "        for m in messages:\n",
    "            pretty_print_message(m, indent=is_subgraph)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d096ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool, initialize_agent\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.tools import tool\n",
    "from langgraph.graph import END, StateGraph\n",
    "from typing import List, Dict\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from langsmith import traceable\n",
    "from langsmith.wrappers import wrap_openai\n",
    "\n",
    "LANGSMITH_TRACING=\"true\"\n",
    "LANGSMITH_ENDPOINT=\"https://api.smith.langchain.com\"\n",
    "LANGSMITH_PROJECT=\"news-agent\"\n",
    "\n",
    "\n",
    "TARGET_AUTHORS = {\n",
    "    \"HLInvest\"\n",
    "}\n",
    "\n",
    "TARGET_DATE = \"25 July 2025\"  # Change as needed\n",
    "HEADERS = {\"User-Agent\": \"Mozilla/5.0 (compatible; NewsScraper/1.0)\"}\n",
    "BASE_URL = \"https://klse.i3investor.com\"\n",
    "IMAGE_FOLDER = \"technical_charts\"\n",
    "\n",
    "\n",
    "# -- 2.1 Headline Extraction Agent --\n",
    "@tool\n",
    "def parse_headlines_agent():\n",
    "    \"\"\"\n",
    "    Getting the news headlines from the i3investor blog page.\n",
    "    \"\"\"\n",
    "    url = f\"{BASE_URL}/web/headline/blog?type=research\"\n",
    "    resp = requests.get(url, headers=HEADERS, timeout=10)\n",
    "    resp.raise_for_status()\n",
    "\n",
    "    html = resp.text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    container = soup.select_one(\"#news-blog\")\n",
    "    results = []\n",
    "\n",
    "    current_date = None\n",
    "    for el in container.find_all(recursive=False):\n",
    "        h5 = el.select_one(\"h5\")\n",
    "        if h5:\n",
    "            match = re.search(r\"\\d{1,2} \\w+ \\d{4}\", h5.text)\n",
    "            if match:\n",
    "                current_date = match.group(0)\n",
    "            continue\n",
    "\n",
    "        if el.name == \"ul\" and \"ms-4\" in el.get(\"class\", []):\n",
    "            li = el.select_one(\"li\")\n",
    "            if not li:\n",
    "                continue\n",
    "            a_tag = li.find(\"a\", href=True)\n",
    "            subtitle = li.select_one(\"span.subtitle a\")\n",
    "            if not a_tag or not subtitle:\n",
    "                continue\n",
    "            author = subtitle.text.strip()\n",
    "            if author not in TARGET_AUTHORS:\n",
    "                continue\n",
    "            if current_date != TARGET_DATE:\n",
    "                continue\n",
    "\n",
    "            full_url = a_tag[\"href\"] if a_tag[\"href\"].startswith(\"http\") else BASE_URL + a_tag[\"href\"]\n",
    "\n",
    "            results.append(\n",
    "                f\"Title: {a_tag.text.strip()} (Author: {author}, Date: {current_date}, URL: {full_url})\"\n",
    "            )\n",
    "\n",
    "    paragraph = \"Today's headlines:\\n\" + \"\\n\".join(results) if results else \"No headlines found for today.\"\n",
    "    return {\"paragraph\": paragraph}\n",
    "\n",
    "# -- 2.2 Blog Parser Agent (content structuring) --\n",
    "@tool\n",
    "def parse_blog_content_agent(item: Dict) -> Dict:\n",
    "    \"\"\"Fetches and parses blog post content from url and extracts clean text and images.\"\"\"\n",
    "    url = item[\"url\"]\n",
    "    resp = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"}, timeout=10)\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "    content_div = soup.select_one(\"#blogcontent\")\n",
    "    if not content_div:\n",
    "        item[\"content\"] = \"\"\n",
    "        return item\n",
    "    paragraphs = [tag.get_text(strip=True) for tag in content_div.find_all([\"h3\", \"p\", \"li\"])]\n",
    "    images = [img[\"src\"] for img in content_div.find_all(\"img\") if img.get(\"src\")]\n",
    "    item[\"content\"] = \"\\n\".join(paragraphs)\n",
    "    item[\"images\"] = [src.split(\"/\")[-1] for src in images]  # Save only filenames\n",
    "    return item\n",
    "\n",
    "\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    # reasoning_format=\"hidden\",\n",
    "    timeout=None,\n",
    "    max_retries=0,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdd3e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "\n",
    "parse_headlines_agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=[parse_headlines_agent],\n",
    "    prompt=(\n",
    "        \"You are a headlines research (including title, author, urls, date) agent.\\n\\n\"\n",
    "        \"INSTRUCTIONS:\\n\"\n",
    "        \"- Assist ONLY getting the headlines tasks, DO NOT do any deep crawling\\n\"\n",
    "        \"- After you're done with your tasks, respond to the supervisor directly\\n\"\n",
    "        \"- Respond ONLY with the results of your work, do NOT include ANY other text.\"\n",
    "    ),\n",
    "    name=\"parse_headlines_agent\",\n",
    ")\n",
    "\n",
    "\n",
    "parse_blog_content_agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=[parse_blog_content_agent],\n",
    "    prompt=(\n",
    "        \"You are a web-scraping for detailed blog page agent. DO NOT use this if user only request to know the headlines\\n\\n\"\n",
    "        \"INSTRUCTIONS:\\n\"\n",
    "        \"- Assist ONLY with extracting blog post content from url and extracts clean text and images tasks\\n\"\n",
    "        \"- After you're done with your tasks, respond to the supervisor directly\\n\"\n",
    "        \"- Respond ONLY with the results of your work, do NOT include ANY other text.\"\n",
    "    ),\n",
    "    name=\"parse_blog_content_agent\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72f2700c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update from node supervisor:\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: transfer_to_parse_headlines_agent\n",
      "\n",
      "Successfully transferred to parse_headlines_agent\n",
      "\n",
      "\n",
      "Update from node parse_headlines_agent:\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: parse_headlines_agent\n",
      "\n",
      "{\"headlines\": [{\"title\": \"Traders Brief - HLIB Retail Research –25 July\", \"author\": \"HLInvest\", \"date\": \"25 July 2025\", \"url\": \"https://klse.i3investor.com/web/blog/detail/hleresearch/2025-07-25-story-h499657040-Traders_Brief_HLIB_Retail_Research_ndash_25_July\"}]}\n",
      "\n",
      "\n",
      "Update from node supervisor:\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: supervisor\n",
      "\n",
      "The news headlines for 25 July 2025 is \"Traders Brief - HLIB Retail Research –25 July\" by HLInvest.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "from langchain_core.tools import tool, InjectedToolCallId\n",
    "from langgraph.prebuilt import InjectedState\n",
    "from langgraph.graph import StateGraph, START, MessagesState\n",
    "from langgraph.types import Command\n",
    "\n",
    "\n",
    "def create_handoff_tool(*, agent_name: str, description: str | None = None):\n",
    "    name = f\"transfer_to_{agent_name}\"\n",
    "    description = description or f\"Ask {agent_name} for help.\"\n",
    "\n",
    "    @tool(name, description=description)\n",
    "    def handoff_tool(\n",
    "        state: Annotated[MessagesState, InjectedState],\n",
    "        tool_call_id: Annotated[str, InjectedToolCallId],\n",
    "    ) -> Command:\n",
    "        tool_message = {\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": f\"Successfully transferred to {agent_name}\",\n",
    "            \"name\": name,\n",
    "            \"tool_call_id\": tool_call_id,\n",
    "        }\n",
    "        return Command(\n",
    "            goto=agent_name,  \n",
    "            update={**state, \"messages\": state[\"messages\"] + [tool_message]},  \n",
    "            graph=Command.PARENT,  \n",
    "        )\n",
    "\n",
    "    return handoff_tool\n",
    "\n",
    "\n",
    "# Handoffs\n",
    "assign_to_parse_headlines_agent = create_handoff_tool(\n",
    "    agent_name=\"parse_headlines_agent\",\n",
    "    description=\"Assign task to a parse_headlines agent.\",\n",
    ")\n",
    "\n",
    "assign_to_parse_blog_content_agent = create_handoff_tool(\n",
    "    agent_name=\"parse_blog_content_agent\",\n",
    "    description=\"Assign task to a parse_blog_content agent.\",\n",
    ")\n",
    "\n",
    "\n",
    "supervisor_agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=[assign_to_parse_headlines_agent, assign_to_parse_blog_content_agent],\n",
    "    prompt=(\n",
    "        \"You are a supervisor managing two agents:\\n\"\n",
    "        \"- a news headlines agent. Assign headlines research (including title, author, urls, date) tasks to this agent\\n\"\n",
    "        \"- a blog content agent. Assign extracting detailed blog content tasks to this agent\\n\"\n",
    "        \"Assign work to one agent at a time, do not call agents in parallel.\\n\"\n",
    "        \"After all agents have completed their tasks, answer the user's question using the collected outputs.\"\n",
    "    ),\n",
    "    name=\"supervisor\",\n",
    ")\n",
    "\n",
    "from langgraph.graph import END\n",
    "\n",
    "# Define the multi-agent supervisor graph\n",
    "supervisor = (\n",
    "    StateGraph(MessagesState)\n",
    "    # NOTE: `destinations` is only needed for visualization and doesn't affect runtime behavior\n",
    "    .add_node(supervisor_agent, destinations=(\"parse_headlines_agent\", \"parse_blog_content_agent\", END))\n",
    "    .add_node(parse_headlines_agent)\n",
    "    .add_node(parse_blog_content_agent)\n",
    "    .add_edge(START, \"supervisor\")\n",
    "    # always return back to the supervisor\n",
    "    .add_edge(\"parse_headlines_agent\", \"supervisor\")\n",
    "    .add_edge(\"parse_blog_content_agent\", \"supervisor\")\n",
    "    .compile()\n",
    ")\n",
    "\n",
    "# from IPython.display import display, Image\n",
    "\n",
    "# display(Image(supervisor.get_graph().draw_mermaid_png()))\n",
    "\n",
    "for chunk in supervisor.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What is the news headlines for 25 July 2025?\",\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "):\n",
    "    pretty_print_messages(chunk, last_message=True)\n",
    "\n",
    "final_message_history = chunk[\"supervisor\"][\"messages\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
